{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = pd.read_csv('ActionList-Reduced.csv')\n",
    "#Setting time column from string to Float\n",
    "actions['Time'] = actions['Time'].apply(lambda x: x.replace(',','.')).astype(float)\n",
    "\n",
    "ref = pd.read_csv('RefPostos-Reduced.csv')\n",
    "ref = ref.drop(columns=['Classe Posto','Ordem Atividades','Parte'])\n",
    "#Setting time column from string to Float\n",
    "ref['Tempo (s)'] = ref['Tempo (s)'].apply(lambda x: x.replace(',','.')).astype(float)\n",
    "\n",
    "operators = pd.read_csv('Operadores-Reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Referencia (44 Postos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26a84b43448>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph for referential comparison data\n",
    "ref.groupby('Posto')['Tempo (s)'].sum().plot(kind=\"bar\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Estado Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando TT com o valor inteiro arredondado para cimada ação mais demorada da lista de ações e definindo a sequência inicial como a ordem dos operadores no arquivo de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitialTT():\n",
    "    return math.ceil(max(actions.Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstOperatorsOrder():\n",
    "    \n",
    "    order = []\n",
    "    \n",
    "    for i in range(0,len(operators.Nome)):\n",
    "        order = np.append(order, i)\n",
    "        \n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enums import *\n",
    "import random\n",
    "\n",
    "class LayoutSimulation:\n",
    "    \n",
    "    #def __init__(self, tt=np.max(actions.Time),order = getFirstOperatorsOrder()):   \n",
    "\n",
    "    def take_action(self, action):\n",
    "        if action == 'INCREASE':\n",
    "            self.state[0] = self.state[0] + 1\n",
    "            reward = get_reward(state)\n",
    "        elif action == 'DECREASE':\n",
    "            self.state[0] = self.state[0] - 1\n",
    "            reward = get_reward(state)\n",
    "        else:\n",
    "            aux = self.state[1]\n",
    "            self.state[1] = self.state[action]\n",
    "            self.state[action] = aux\n",
    "            reward = get_reward(state)\n",
    "            \n",
    "        return self.state, reward\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset state to zero, the beginning of the dungeon\n",
    "        self.state = np.concatenate(([getInitialTT()],getFirstOperatorsOrder()))\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from enums import *\n",
    "import random\n",
    "import math\n",
    "\n",
    "class Supervisor:\n",
    "    def __init__(self, learning_rate=0.1, discount=0.95, exploration_rate=1.0, iterations=10000):\n",
    "        self.q_table = [ [ 0 for i in range(100*math.factorial(len(operators.Nome))) ] for j in range(len(operators.Nome)+2)] # Spreadsheet (Q-table) for rewards accounting\n",
    "        self.learning_rate = learning_rate # How much we appreciate new q-value over current\n",
    "        self.discount = discount # How much we appreciate future reward over current\n",
    "        self.exploration_rate = 1.0 # Initial exploration rate\n",
    "        self.exploration_delta = 1.0 / iterations # Shift from exploration to explotation\n",
    "\n",
    "    def get_next_action(self, state):\n",
    "        if random.random() > self.exploration_rate: # Explore (gamble) or exploit (greedy)\n",
    "            return self.greedy_action(state)\n",
    "        else:\n",
    "            return self.random_action()\n",
    "\n",
    "    def greedy_action(self, state):\n",
    "        \n",
    "        best_action = numpy.max(max(self.q_table[state]) \n",
    "        # Is FORWARD reward is bigger?\n",
    "        if self.q_table[INCREASE][state] > self.q_table[DECREASE][state]:\n",
    "            return FORWARD\n",
    "        # Is BACKWARD reward is bigger?\n",
    "        elif self.q_table[BACKWARD][state] > self.q_table[FORWARD][state]:\n",
    "            return BACKWARD\n",
    "        # Rewards are equal, take random action\n",
    "        return FORWARD if random.random() < 0.5 else BACKWARD\n",
    "\n",
    "    def random_action(self):\n",
    "        rand = random.randint(0, len(operators.Time) + 1)\n",
    "        if(rand == 0):\n",
    "            return INCREASE\n",
    "        if(rand == 1):\n",
    "            return DECREASE\n",
    "        else:\n",
    "            return rand\n",
    "\n",
    "    def update(self, old_state, new_state, action, reward):\n",
    "        # Old Q-table value\n",
    "        old_value = self.q_table[action][old_state]\n",
    "        # What would be our best next action?\n",
    "        future_action = self.greedy_action(new_state)\n",
    "        # What is reward for the best next action?\n",
    "        future_reward = self.q_table[future_action][new_state]\n",
    "\n",
    "        # Main Q-table updating algorithm\n",
    "        new_value = old_value + self.learning_rate * (reward + self.discount * future_reward - old_value)\n",
    "        self.q_table[action][old_state] = new_value\n",
    "\n",
    "        # Finally shift our exploration_rate toward zero (less gambling)\n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate -= self.exploration_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 12000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agente = Supervisor()\n",
    "np.array(agente.q_table).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "def SimulationStart():\n",
    "    # parse arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1, help='How quickly the algorithm tries to learn')\n",
    "    parser.add_argument('--discount', type=float, default=0.95, help='Discount for estimated future action')\n",
    "    parser.add_argument('--iterations', type=int, default=2000, help='Iteration count')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "    agent = Supervisor()\n",
    "\n",
    "    # setup simulation\n",
    "    line_layout = LayoutSimulation()\n",
    "    line_layout.reset()\n",
    "    total_reward = 0 # Score keeping\n",
    "\n",
    "    #Main loop\n",
    "    for step in range(FLAGS.iterations):\n",
    "        old_state = line_layout.state # Store current state\n",
    "        action = agent.get_next_action(old_state) # Query agent for the next action\n",
    "        new_state, reward = dungeon.take_action(action) # Take action, get new state and reward\n",
    "        agent.update(old_state, new_state, action, reward) # Let the agent update internals\n",
    "\n",
    "        total_reward += reward # Keep score\n",
    "        if step % 250 == 0: # Print out metadata every 100th iteration\n",
    "            print(json.dumps({'step': step, 'total_reward': total_reward}))\n",
    "\n",
    "        time.sleep(0.0001) # Avoid spamming stdout too fast!\n",
    "\n",
    "    print(\"Final Q-table\", agent.q_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Iniciar Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-e4373f5ab8bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSimulationStart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-d665ad9f4d8c>\u001b[0m in \u001b[0;36mSimulationStart\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mold_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline_layout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;31m# Store current state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Query agent for the next action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdungeon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Take action, get new state and reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Let the agent update internals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-3663203ce22e>\u001b[0m in \u001b[0;36mget_next_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgreedy_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgreedy_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-3663203ce22e>\u001b[0m in \u001b[0;36mrandom_action\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrandom_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mrand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mINCREASE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_count' is not defined"
     ]
    }
   ],
   "source": [
    "SimulationStart()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
