{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = pd.read_csv('ActionList-Reduced.csv')\n",
    "#Setting time column from string to Float\n",
    "actions['Time'] = actions['Time'].apply(lambda x: x.replace(',','.')).astype(float)\n",
    "\n",
    "ref = pd.read_csv('RefPostos-Reduced.csv')\n",
    "ref = ref.drop(columns=['Classe Posto','Ordem Atividades','Parte'])\n",
    "#Setting time column from string to Float\n",
    "ref['Tempo (s)'] = ref['Tempo (s)'].apply(lambda x: x.replace(',','.')).astype(float)\n",
    "\n",
    "operators = pd.read_csv('Operadores-Reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18d7baf8ec8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph for referential comparison data\n",
    "ref.groupby('Posto')['Tempo (s)'].sum().plot(kind=\"bar\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Estado Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando TT com o valor inteiro arredondado para cimada ação mais demorada da lista de ações e definindo a sequência inicial como a ordem dos operadores no arquivo de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitialTT():\n",
    "    return math.ceil(max(actions.Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstOperatorsOrder():\n",
    "    \n",
    "    order = []\n",
    "    \n",
    "    for i in range(0,len(operators.Nome)):\n",
    "        order = np.append(order, i)\n",
    "        \n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStateNumber(state):\n",
    "    state_number = 0\n",
    "    \n",
    "    state_number = state_number + state[0]*6**5\n",
    "    \n",
    "    state_number = state_number + state[1]*1\n",
    "    state_number = state_number + state[2]*6**1\n",
    "    state_number = state_number + state[3]*6**2\n",
    "    state_number = state_number + state[4]*6**3\n",
    "    state_number = state_number + state[5]*6**4\n",
    "    \n",
    "    return int(state_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(tt,order): \n",
    "\n",
    "    #Definindo tempo total somado das atividades\n",
    "    total_time = actions.Time.sum()\n",
    "\n",
    "    #Definindo a distribuição sequencial baseada em TT e order\n",
    "    accumulator = 0\n",
    "    full_time = 0\n",
    "    time_posto = [0] * len(operators.Nome)\n",
    "    index = 0\n",
    "    action_num = 0\n",
    "\n",
    "    while(action_num < len(actions.Time)-1 and index < len(operators.Nome)):\n",
    "\n",
    "        while accumulator < tt-actions.Time[action_num]*operators.Eficiencia[order[index]]:\n",
    "            if(action_num < len(actions.Time)-1):\n",
    "                accumulator = accumulator + actions.Time[action_num]*operators.Eficiencia[order[index]]\n",
    "                action_num = action_num + 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        time_posto[index] = accumulator \n",
    "        full_time = full_time + accumulator\n",
    "        accumulator = 0\n",
    "        index = index + 1\n",
    "        \n",
    "    missing_actions = len(actions.Time)-1 - action_num \n",
    "    not_working_operators = len(operators.Nome) - np.count_nonzero(time_posto)\n",
    "    mean_time = time_posto[time_posto!=0].mean()\n",
    "    max_time = np.max(time_posto)\n",
    "\n",
    "    #Printa valores de saída se flag acionada\n",
    "    \n",
    "    print('INPUT')\n",
    "    print(f'Tempo Maximo/Posto: {tt}')\n",
    "    print(f'Ordem dos Operadores: {order}')\n",
    "    print('')\n",
    "    print('OUTPUT')\n",
    "    print(f'Ações faltando: {missing_actions}')\n",
    "    print(f'Operadores sem Trabalho: {not_working_operators}')\n",
    "    print(f'Tempo Maximo no posto: {max_time}')\n",
    "\n",
    "    print('')\n",
    "\n",
    "   # print(f'SCORE: {getEvaluation(missing_actions,not_working_operators,max_time)}')\n",
    "    \n",
    "    pd.DataFrame(time_posto).plot(kind=\"bar\",figsize=(10,5),legend=0)\n",
    "    \n",
    "    if(missing_actions > 0 or not_working_operators > 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state):\n",
    "\n",
    "        total_time = state[0]\n",
    "        order = state[1:len(state)-1]\n",
    "\n",
    "        #Definindo a distribuição sequencial baseada em TT e order\n",
    "        accumulator = 0\n",
    "        full_time = 0\n",
    "        time_posto = [0] * (len(state)-1)\n",
    "        index = 0\n",
    "        action_num = 0\n",
    "\n",
    "        while(action_num < len(actions.Time)-1 and index < len(operators.Nome)):\n",
    "\n",
    "            while accumulator < state[0]-actions.Time[action_num]*operators.Eficiencia[order[index-1]]:\n",
    "                if(action_num < len(actions.Time)-1):\n",
    "                    accumulator = accumulator + actions.Time[action_num]*operators.Eficiencia[order[index-1]]\n",
    "                    action_num = action_num + 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            time_posto[index] = accumulator \n",
    "            full_time = full_time + accumulator\n",
    "            accumulator = 0\n",
    "            index = index + 1\n",
    "\n",
    "        missing_actions = len(actions.Time)-1 - action_num \n",
    "        not_working_operators = len(operators.Nome) - np.count_nonzero(time_posto)\n",
    "        mean_time = time_posto[time_posto!=0].mean()\n",
    "        max_time = np.max(time_posto)\n",
    "\n",
    "        if(missing_actions > 0 or not_working_operators > 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return max_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enums import *\n",
    "import random\n",
    "\n",
    "class LayoutSimulation:\n",
    "    \n",
    "    #def __init__(self, tt=np.max(actions.Time),order = getFirstOperatorsOrder()):   \n",
    "\n",
    "    def take_action(self, action):\n",
    "        if action == 'INCREASE':\n",
    "            self.state[0] = self.state[0] + 1\n",
    "            reward = get_reward(self.state)\n",
    "        elif action == 'DECREASE':\n",
    "            self.state[0] = self.state[0] - 1\n",
    "            reward = get_reward(self.state)\n",
    "        else:\n",
    "            aux = self.state[1]\n",
    "            self.state[1] = self.state[action]\n",
    "            self.state[action] = aux\n",
    "            reward = get_reward(self.state)\n",
    "            \n",
    "        return self.state, reward\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset state to zero, the beginning of the dungeon\n",
    "        self.state = np.concatenate(([getInitialTT()],getFirstOperatorsOrder()))\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from enums import *\n",
    "import random\n",
    "import math\n",
    "\n",
    "class Supervisor:\n",
    "    def __init__(self, learning_rate=0.1, discount=0.95, exploration_rate=1.0, iterations=10000):\n",
    "        #self.q_table = [ [ 0 for i in range(100*math.factorial(len(operators.Nome))) ] for j in range(len(operators.Nome)+1)] # Spreadsheet (Q-table) for rewards accounting\n",
    "        self.q_table = [ [ 0 for i in range(len(operators.Nome)+1) ] for j in range(785376)]\n",
    "        self.learning_rate = learning_rate # How much we appreciate new q-value over current\n",
    "        self.discount = discount # How much we appreciate future reward over current\n",
    "        self.exploration_rate = 1.0 # Initial exploration rate\n",
    "        self.exploration_delta = 1.0 / iterations # Shift from exploration to exploitation\n",
    "\n",
    "    def get_next_action(self, state):\n",
    "        if random.random() > self.exploration_rate: # Explore (gamble) or exploit (greedy)\n",
    "            return self.greedy_action(state)\n",
    "        else:\n",
    "            return self.random_action()\n",
    "\n",
    "    def greedy_action(self, state):\n",
    "        \n",
    "        # Choose best rewarding action to take\n",
    "        #print(f'{state},{getStateNumber(state)}')\n",
    "        #print(f'{self.q_table[10][5]}')\n",
    "        \n",
    "        best_action = np.max(self.q_table[getStateNumber(state)])\n",
    "        \n",
    "        if best_action == 0:\n",
    "            return 'INCREASE'\n",
    "        if best_action == 1:\n",
    "            return 'DECREASE'\n",
    "        else:\n",
    "            return best_action\n",
    "\n",
    "    def random_action(self):\n",
    "        rand = random.randint(0, len(operators.Nome))\n",
    "        if(rand == 0):\n",
    "            return 'INCREASE'\n",
    "        if(rand == 1):\n",
    "            return 'DECREASE'\n",
    "        else:\n",
    "            return rand\n",
    "\n",
    "    def update(self, old_state, new_state, action, reward):\n",
    "        # Old Q-table value\n",
    "        \n",
    "        #print(f'{action} , {getStateNumber(old_state)}')\n",
    "        old_value = self.q_table[getStateNumber(old_state)][action]\n",
    "        # What would be our best next action?\n",
    "        future_action = self.greedy_action(new_state)\n",
    "        \n",
    "        if(future_action == 'INCREASE'):\n",
    "            future_action = 0\n",
    "        if(future_action == 'DECREASE'):\n",
    "            future_action = 1\n",
    "            \n",
    "        # What is reward for the best next action?\n",
    "        print(f'{getStateNumber(new_state)}, {future_action}')\n",
    "        future_reward = self.q_table[getStateNumber(new_state)][future_action]\n",
    "\n",
    "        # Main Q-table updating algorithm\n",
    "        print(f'Old: {old_value}')\n",
    "        new_value = old_value + self.learning_rate * (reward + self.discount * future_reward - old_value)\n",
    "        self.q_table[getStateNumber(old_state)][action] = new_value\n",
    "\n",
    "        # Finally shift our exploration_rate toward zero (less gambling)\n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate -= self.exploration_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "def SimulationStart():\n",
    "    # parse arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1, help='How quickly the algorithm tries to learn')\n",
    "    parser.add_argument('--discount', type=float, default=0.95, help='Discount for estimated future action')\n",
    "    parser.add_argument('--iterations', type=int, default=2000, help='Iteration count')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "    agent = Supervisor()\n",
    "\n",
    "    # setup simulation\n",
    "    line_layout = LayoutSimulation()\n",
    "    tt = getInitialTT()\n",
    "    order = getFirstOperatorsOrder()\n",
    "    line_layout.reset()\n",
    "    total_reward = 0 # Score keeping\n",
    "\n",
    "    print(f'Estado Inicial: {line_layout.state}')\n",
    "    print('\\n')\n",
    "    #Main loop\n",
    "    for step in range(FLAGS.iterations):\n",
    "        old_state = line_layout.state # Store current state\n",
    "        action = agent.get_next_action(old_state) # Query agent for the next action\n",
    "        print(f'Agente executou ação: {action}')\n",
    "        new_state, reward = line_layout.take_action(action) # Take action, get new state and reward\n",
    "        print(f'Novo Estado: {new_state}')\n",
    "        print(f'Recompensa: {reward}')\n",
    "        print('\\n')\n",
    "        \n",
    "        if(action== 'INCREASE'):\n",
    "            action = 0\n",
    "        if(action== 'DECREASE'):\n",
    "            action = 1\n",
    "        agent.update(old_state, new_state, action, reward) # Let the agent update internals\n",
    "\n",
    "        total_reward += reward # Keep score\n",
    "        if step % 250 == 0: # Print out metadata every 100th iteration\n",
    "            print(json.dumps({'step': step, 'total_reward': total_reward}))\n",
    "\n",
    "        time.sleep(0.0001) # Avoid spamming stdout too fast!\n",
    "\n",
    "    print(\"Final Q-table\", agent.q_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Iniciar Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "Tempo Maximo/Posto: 25\n",
      "Ordem dos Operadores: [2, 3, 1, 0, 4]\n",
      "\n",
      "OUTPUT\n",
      "Ações faltando: 1\n",
      "Operadores sem Trabalho: 0\n",
      "Tempo Maximo no posto: 24.835199999999993\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SimulationStart()\n",
    "#plotGraph(25,[2,3,1,0,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
